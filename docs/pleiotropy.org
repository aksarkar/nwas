#+TITLE: Modeling pleiotropic effects
#+AUTHOR: Abhishek Sarkar
#+EMAIL: aksarkar@uchicago.edu
#+OPTIONS: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t c:nil
#+OPTIONS: creator:comment d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t
#+OPTIONS: num:t p:nil pri:nil stat:t tags:t tasks:t tex:t timestamp:t toc:t
#+OPTIONS: todo:t |:t
#+CREATOR: Emacs 25.1.1 (Org mode 8.2.10)
#+DESCRIPTION:
#+EXCLUDE_TAGS: noexport
#+KEYWORDS:
#+LANGUAGE: en
#+SELECT_TAGS: export

* Introduction

  Suppose we generated data from both mediated and unmediated effects:

  \[ y^1 = x^1 w v + x^1 u + e \]

  If we require that \(w\) explains the gene expression observations, then can
  we accurately estimate \(v\) even if \(u\) is correlated with \(v\)?

  It is biologically plausible for a variant to have both a mediated and an
  unmediated effect? Do we have any documented examples of this? Can we
  eliminate this possibility by considering a large enough region of the genome
  (enough genes)?

* Simulation setup

  - Generate random genotypes in linkage equilibrium

  - Generate Gaussian gene expression from a linear model (PVE = 0.5)

  #+BEGIN_LaTeX
  \[ w_j \mid \text{causal} ~ N(0, 1) \]
  \[ g^0_{ik} \mid \text{causal} ~ x^0 w + e \]
  #+END_LaTeX

  - Generate non-causal gene expression by sampling from a Gaussian with scale
    equal to the simulated expression phenotypic variance.

  \[ g_{ik} \mid \text{not causal} ~ N(0, V[g \mid \causal]) \]

  - Generate GWAS genotypes and expression from the same linear model

  \[ g^1_{ik} \mid \text{causal} ~ x^1 w + e \]

  - Generate pleiotropic unmediated effect (same variant, independent
    effect). Scale to get the desired PVE.

  \[ u \mid \text{causal} = N(0, V[x^1 w]) \]

  - Generate Gaussian phenotypes by adding noise to get the desired PVE.

  \[ y^1 \mid N(g^1 v + x^1 u, \sigma^2) \]

  #+BEGIN_SRC python :tangle pleiotropy.py :exports none
    import edward as ed
    import numpy
    import nwas
    import scipy.special
    import tensorflow as tf

    from edward.models import *
    from nwas.models import *

    p = 100  # Number of SNPs
    m = 10  # Number of genes
    n_ref = 500
    n_gwas = 10000
    pve_g = 0.5
    pve_u = 0.01  # Proportion of phenotypic variance explained by unmediated effects
    pve_m = 0.01

    with nwas.simulation.simulation(p, pve_g, [(3, 1)], 0) as s:
        x_ref, g_ref = s.sample_gaussian(n=n_ref)
        g_noise = s.random.normal(scale=numpy.sqrt(s.pheno_var), size=(n_ref, m - 1))
        g_ref = numpy.hstack((g_ref.reshape(-1, 1), g_noise))
        x_gwas, g_gwas = s.sample_gaussian(n=n_gwas)

        # True mediated effect size of 1
        y_gwas = numpy.copy(g_gwas)

        # Pleiotropic (unmediated) effects
        u = numpy.zeros(p)
        causal = s.theta != 0
        u[causal] = numpy.random.normal(scale=numpy.sqrt(y_gwas.var()), size=causal.sum())
        y_gwas += x_gwas.dot(u)

        # Add residual
        y_gwas += s.random.normal(scale=numpy.sqrt(y_gwas.var() * (1 / (pve_u + pve_m) - 1)), size=n_gwas)

        # Center
        y_gwas -= y_gwas.mean()

        x_ref = x_ref.astype('float32')
        g_ref = g_ref.astype('float32')
        x_gwas = x_gwas.astype('float32')
        y_gwas = y_gwas.reshape(-1, 1).astype('float32')

        print('Mediated PVE = {:.3f}'.format(g_gwas.var() / y_gwas.var()))
        print('Unmediated PVE = {:.3f}'.format(x_gwas.dot(u).var() / y_gwas.var()))
  #+END_SRC

* Joint model

  #+BEGIN_SRC python :tangle pleiotropy.py
    ed.set_seed(0)

    # Data
    x0 = tf.placeholder(tf.float32)
    x1 = tf.placeholder(tf.float32)

    # eQTL effects
    Hm, if it were n and nlogodds_w = Normal(loc=tf.constant(-10.0), scale=tf.ones(1))
    scale_w = Normal(loc=tf.zeros(1), scale=tf.ones(1))
    w = SpikeSlab(logodds=logodds_w, loc=tf.zeros([p, m]), scale=scale_w)
    # This is a dummy which gets swapped out in the inference
    eta0 = LocalReparameterization(Normal(tf.matmul(x0, w), 1.0))
    g0 = NormalWithSoftplusScale(
        loc=eta0, scale=tf.Variable(tf.random_normal([1])))

    # Mediated gene effects
    logodds_v = Normal(loc=tf.constant(-10.0), scale=tf.ones(1))
    scale_v = Normal(loc=tf.zeros(1), scale=tf.ones(1))
    v = SpikeSlab(logodds=tf.Variable(-numpy.log(m).astype('float32')),
                  loc=tf.zeros([m, 1]), scale=tf.Variable(0.0))
    eta1 = LocalReparameterization(Normal(tf.matmul(tf.matmul(x1, w), v), 1.0))
    y1 = NormalWithSoftplusScale(loc=eta1, scale=tf.Variable(0.0))
  #+END_SRC

* Variational approximation

  #+BEGIN_SRC python :tangle pleiotropy.py
    q_logodds_w = Normal(loc=tf.Variable(tf.random_normal([1])),
                         scale=tf.Variable(tf.random_normal([1])))
    q_logodds_v = Normal(loc=tf.Variable(tf.random_normal([1])),
                         scale=tf.Variable(tf.random_normal([1])))
    q_scale_w = Normal(loc=tf.Variable(tf.random_normal([1])),
                       scale=tf.Variable(tf.random_normal([1])))
    q_scale_v = Normal(loc=tf.Variable(tf.random_normal([1])),
                       scale=tf.Variable(tf.random_normal([1])))

    q_w = SpikeSlab(logodds=tf.Variable(tf.zeros([p, m])),
                    loc=tf.Variable(tf.random_normal([p, m])),
                    scale=tf.Variable(tf.zeros([p, m])))
    q_eta0 = LocalReparameterization(
        Normal(loc=tf.matmul(x0, q_w.mean()),
               scale=tf.sqrt(tf.matmul(tf.square(x0), q_w.variance()))))
  #+END_SRC

  We need to do some work to get the reparameterized distribution \(q(X w
  v)\). As previously derived (Brown 1977), if b, c are \(n\)-dimensional
  Gaussian then:

  \[ E[b' c] = E[b]' E[c] \]

  \[ V[b' c] = E[b]' Cov(c, c) E[b] + E[c]' Cov(b, b) + E[c] \]

  Here, we need moments of a stochastic matrix-vector product. However, under the
  variational approximation, all of the elements are independent, simplifying the
  derivation. Let \(\eta = X w\). Then considering each row \(\eta_i\), we can
  simply apply the above result to get:

  \[ E_q[\eta_i v] = E_q[\eta_i] E_q[v] \]

  \[ V_q[\eta_i v] = E_q[\eta_i] \diag(V_q[v]) E_q[\eta_i]' + E_q[v]' \diag(V_q[\eta_i]) E_q[v] \]

  #+BEGIN_SRC python :tangle pleiotropy.py
    q_v = SpikeSlab(logodds=tf.Variable(tf.zeros([m, 1])),
                    loc=tf.Variable(tf.random_normal([m, 1])),
                    scale=tf.Variable(tf.zeros([m, 1])))
    # Conviently keep the necessary mean and variance around
    q_eta1 = Normal(loc=tf.matmul(x1, q_w.mean()),
                    scale=tf.sqrt(tf.matmul(tf.square(x1), q_w.variance())))
    var = (tf.reduce_sum(tf.square(q_eta1.mean()) *
                         tf.transpose(q_v.variance()), axis=1, keep_dims=True) +
           tf.reduce_sum(tf.transpose(tf.square(q_v.mean())) *
                         q_eta1.variance(), axis=1, keep_dims=True))
    q_eta1 = LocalReparameterization(
        Normal(loc=tf.matmul(tf.matmul(x1, q_w.mean()), q_v.mean()),
               scale=tf.sqrt(var)))
  #+END_SRC

* Model fitting

  #+BEGIN_SRC python :tangle pleiotropy.py
    inference = ed.ReparameterizationKLKLqp(
        latent_vars={
            logodds_w: q_logodds_w,
            logodds_v: q_logodds_v,
            scale_w: q_scale_w,
            scale_v: q_scale_v,
            w: q_w,
            v: q_v,
            eta0: q_eta0,
            eta1: q_eta1,
        },
        data={
            x0: x_ref,
            g0: g_ref,
            x1: x_gwas,
            y1: y_gwas,
        })
    inference.run(n_iter=2000, optimizer='rmsprop')
  #+END_SRC
* Model evaluation

  #+BEGIN_SRC python :tangle pleiotropy.py
    import matplotlib.gridspec
    import matplotlib.pyplot as plt

    sess = ed.get_session()
    w = sess.run(q_w.pip)
    v = sess.run(q_v.pip)

    plt.switch_backend('pdf')
    gs = matplotlib.gridspec.GridSpec(1, 2, width_ratios=[100, 1])
    fig = plt.gcf()
    fig.set_size_inches(8, 2)
    plt.clf()
    plt.subplot(gs[0])
    plt.imshow(w.T, cmap='Greys')
    ax = plt.gca()
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_xticklabels([])
    ax.set_yticklabels([])
    ax.set_xlabel('Variants')
    ax.set_ylabel('Genes')

    plt.subplot(gs[1])
    plt.imshow(v, cmap='Greys')
    ax = plt.gca()
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_xticklabels([])
    ax.set_yticklabels([])
    ax.set_ylabel('Genes')
    plt.savefig('coefficients')
    plt.close()
  #+END_SRC

* Limitations

  Suppose we generated data from both mediated and unmediated effects:

  \[ y^1 = x^1 w v + x^1 u + e \]

  If we jointly fit mediated and unmediated effects in the model, unmediated
  effects explain away the mediated effects. Unclear whether this happens
  because the simulation is trivial, so that \(w\) and \(v\) really can
  co-adapt.

  If we leave unmediated effects out, but require that \(w\) explains the gene
  expression observations, then can we accurately estimate \(v\) assuming that
  \(u\) is uncorrelated with \(v\)?

  Of course, \(u\) correlated with \(v\) is the well studied pleiotropy problem
  in Mendelian randomization.

  To make causal claims, we further need to remove /trans/-effects and reverse
  causal effects on gene expression.

  We can do the first using half-sibling regression (regress observed genes
  expression against control gene expression, where control genes are on other
  chromosomes).

  We can do the second using a random effects approach. Suppose we regress gene
  expression against phenotype, assuming a linear mixed model where the kernel
  matrix is built on the rest of the genome.
