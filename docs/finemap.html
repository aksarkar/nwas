<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2017-10-30 Mon 18:11 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Fine mapping idea</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Abhishek Sarkar">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Fine mapping idea</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org6d209cc">1. Proposed model</a></li>
<li><a href="#orgd39e322">2. Variational lower bound</a></li>
<li><a href="#orga668614">3. Setup</a></li>
<li><a href="#orgeb93080">4. Simulated data and existing method</a></li>
<li><a href="#org93bb08b">5. Coordinate ascent</a></li>
<li><a href="#orgcd228b8">6. SGVB on same objective</a></li>
<li><a href="#org0e00475">7. Continuous relaxation</a></li>
<li><a href="#org991f5e1">8. Dirichlet-Multinomial model</a></li>
</ul>
</div>
</div>

<div id="outline-container-org6d209cc" class="outline-2">
<h2 id="org6d209cc"><span class="section-number-2">1</span> Proposed model</h2>
<div class="outline-text-2" id="text-1">
<p>
Revise the notation, using Latin for the model and Greek for the variational
approximation.
</p>

<p>
\[ p(\mathbf{y} \mid \mathbf{x}, \mathbf{w}) = N(\mathbf{y}; \mathbf{x} \mathbf{w}', v^{-1} \mathbf{I}) \]
\[ \mathbf{w} = \sum_k z_{kj} b_{kj} \]
\[ p(z_k, \mathbf{p}) = \mathrm{Multinomial}(1, \mathbf{p}) \]
\[ p(b_{kj} \mid z_k = 1, v, v_b) = N(0, v^{-1} v_b^{-1}) \]
\[ q(z_k \mid \pi) = \mathrm{Multinomial}(1, \mathbf{\pi}) \]
\[ q(b_{kj} \mid \mu, \phi) = N(\mu_{kj}, \phi_{kj}^{-1}) \]
</p>
</div>
</div>

<div id="outline-container-orgd39e322" class="outline-2">
<h2 id="orgd39e322"><span class="section-number-2">2</span> Variational lower bound</h2>
<div class="outline-text-2" id="text-2">
<p>
\[ \mathrm{ELBO} = \mathbb{E}_q[p(\mathbf{y} \mid \mathbf{x}, \mathbf{w})] -
  KL(q(\mathbf{z}) \Vert p(\mathbf{z})) - KL(q(\mathbf{b}) \Vert p(\mathbf{b}))
  \]
\[ \mathbb{E}_q[p(\mathbf{y} \mid \mathbf{x}, \mathbf{w})] = -\frac{v}{2} \sum_i
  \left(y_i - \sum_j x_{ij} \mathbb{E}_q[w_j]\right)^2 - \sum_{i,j} x_{ij}^2 \mathbb{V}_q[w_j] \]
</p>

<p>
\[ \mathbb{E}_q[w_j] = \sum_k \pi_{kj} \mu_{kj} \]
\[ \mathbb{V}_q[w_j] = \sum_k \pi_{kj} \phi_{kj}^{-1} + \pi_{kj} (1 - \pi_{kj}) \mu_{kj}^2 \]
</p>

<p>
\[ KL(q(\mathbf{z}) \Vert p(\mathbf{z})) = \sum_k E_q[\ln q(z_k) - \ln p(z_k)] \]
\[ = \sum_k \left[\sum_j \pi_{kj} \ln \pi_{kj} - \sum_j \pi_{kj} \ln p_{k}\right] \]
\[ = \sum_{j,k} \pi_{kj} \left( \ln \pi_{kj} - \ln p_{k} \right) \]
</p>

<p>
\[ KL(q(\mathbf{b}) \Vert p(\mathbf{b})) = \frac{1}{2} \sum_{j,k} 1 + \ln (v
  v_b) - \ln \phi_{kj} + v v_b (\mu_{kj}^2 + \phi_{kj}^{-1})\]
</p>
</div>
</div>

<div id="outline-container-orga668614" class="outline-2">
<h2 id="orga668614"><span class="section-number-2">3</span> Setup</h2>
<div class="outline-text-2" id="text-3">
<div class="org-src-container">
<pre class="src src-shell" id="orgdfa5ddf">sbatch --partition=broadwl --mem=16G --time=36:00:00 --job-name=ipython3 --output=ipython3.out
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate nwas
rm -f $<span class="org-variable-name">HOME</span>/.local/share/jupyter/runtime/kernel-aksarkar.json
ipython3 kernel --ip=$(<span class="org-sh-quoted-exec">hostname</span> -i) -f kernel-aksarkar.json
</pre>
</div>

<pre class="example">
Submitted batch job 39720215

</pre>

<div class="org-src-container">
<pre class="src src-ipython" id="orgd16a2bc">%matplotlib inline
<span class="org-keyword">import</span> edward <span class="org-keyword">as</span> ed
<span class="org-keyword">import</span> matplotlib.pyplot <span class="org-keyword">as</span> plt
<span class="org-keyword">import</span> nwas
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> pyplink
<span class="org-keyword">import</span> tensorflow <span class="org-keyword">as</span> tf
</pre>
</div>
</div>
</div>

<div id="outline-container-orgeb93080" class="outline-2">
<h2 id="orgeb93080"><span class="section-number-2">4</span> Simulated data and existing method</h2>
<div class="outline-text-2" id="text-4">
<div class="org-src-container">
<pre class="src src-ipython" id="org11c2416"><span class="org-keyword">with</span> nwas.simulation.simulation(p=1000, pve=0.5, annotation_params=[(10, 1)], seed=0) <span class="org-keyword">as</span> s:
  <span class="org-variable-name">x</span>, <span class="org-variable-name">y</span> = s.sample_gaussian(n=500)
  <span class="org-variable-name">x</span> = x.astype(<span class="org-string">'float32'</span>)
  <span class="org-variable-name">y</span> = y.reshape(-1, 1).astype(<span class="org-string">'float32'</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython" id="org98a1ac9"><span class="org-variable-name">opt</span> = nwas.sgvb.gaussian_spike_slab(x, y, stoch_samples=10)

plt.clf()
<span class="org-variable-name">q</span> = np.logical_or(s.theta != 0, opt[0].ravel() &gt; 0.1)
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(3, 1, sharex=<span class="org-constant">True</span>)
fig.set_size_inches(6, 8)
ax[0].bar(np.arange(np.<span class="org-builtin">sum</span>(q)), s.theta[q])
ax[0].set_ylabel(<span class="org-string">'True effect size'</span>)
ax[1].bar(np.arange(np.<span class="org-builtin">sum</span>(q)), opt[1].ravel()[q])
ax[1].set_ylabel(<span class="org-string">'Estimated effect size'</span>)
ax[2].bar(np.arange(np.<span class="org-builtin">sum</span>(q)), opt[0].ravel()[q])
ax[2].set_ylabel(<span class="org-string">'Posterior inclusion probability'</span>)
ax[2].set_xlabel(<span class="org-string">'True and false positive variants'</span>)
</pre>
</div>

<pre class="example">
&lt;matplotlib.text.Text at 0x2b137360ec18&gt;

</pre>

<div class="figure">
<p><img src="spike-slab-fit.png" alt="spike-slab-fit.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org93bb08b" class="outline-2">
<h2 id="org93bb08b"><span class="section-number-2">5</span> Coordinate ascent</h2>
<div class="outline-text-2" id="text-5">
<p>
Between the old approximation and this approximation, the only difference is
\(KL\left(q(z)\Vert p(z)\right)\), but it has similar form. This suggests
that the same update would work.
</p>

<p>
The real problem is that the optimization is now constrained to have \(\pi\)
on the probability simplex, which isn't captured in the objective function.
</p>

<p>
Normalizing \(\pi_k\) after each update does not increase the ELBO.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org7620495"><span class="org-keyword">def</span> <span class="org-function-name">elbo</span>(x, y, pip, mean, var, effect_var, residual_var):
  <span class="org-variable-name">n</span>, <span class="org-variable-name">p</span> = x.shape
  <span class="org-variable-name">genetic_value_mean</span> = np.dot(x, (pip * mean).<span class="org-builtin">sum</span>(axis=0, keepdims=<span class="org-constant">True</span>).T)
  <span class="org-variable-name">genetic_value_var</span> = np.dot(np.square(x), (pip * var.T + pip * (1 - pip) * np.square(mean)).<span class="org-builtin">sum</span>(axis=0, keepdims=<span class="org-constant">True</span>).T)
  <span class="org-variable-name">llik</span> = -.5 / residual_var * (np.square(y - genetic_value_mean).<span class="org-builtin">sum</span>() - genetic_value_var).<span class="org-builtin">sum</span>()
  <span class="org-comment-delimiter"># </span><span class="org-comment">Assume prior probability 1/p for each variant</span>
  <span class="org-variable-name">kl_z</span> = (pip * (np.log(pip) + np.log(p))).<span class="org-builtin">sum</span>()
  <span class="org-variable-name">kl_b</span> = .5 * (1 + np.log(effect_var * residual_var) - np.log(var.T) + (np.square(mean) + var.T) / (effect_var * residual_var)).<span class="org-builtin">sum</span>()
  <span class="org-keyword">return</span> llik, kl_z, kl_b

<span class="org-keyword">def</span> <span class="org-function-name">coordinate_ascent</span>(x, y, effect_var, residual_var, l=5, num_epochs=200, verbose=<span class="org-constant">False</span>):
  <span class="org-variable-name">n</span>, <span class="org-variable-name">p</span> = x.shape
  <span class="org-variable-name">pi</span> = np.ones((p, 1))
  <span class="org-variable-name">d</span> = np.einsum(<span class="org-string">'ij,ij-&gt;j'</span>, x, x).reshape(-1, 1)
  <span class="org-variable-name">xy</span> = x.T.dot(y)
  <span class="org-variable-name">pip</span> = np.zeros((l, p))
  <span class="org-variable-name">mean</span> = np.zeros((l, p))
  <span class="org-comment-delimiter"># </span><span class="org-comment">Make sure everything is two dimensional to catch numpy broadcasting gotchas</span>
  <span class="org-variable-name">var</span> = (effect_var * residual_var / (effect_var * d + 1)).reshape(-1, 1)
  <span class="org-variable-name">eta</span> = np.dot(x, (pip * mean).<span class="org-builtin">sum</span>(axis=0, keepdims=<span class="org-constant">True</span>).T)
  <span class="org-variable-name">elbo_</span> = <span class="org-constant">None</span>
  <span class="org-keyword">for</span> epoch <span class="org-keyword">in</span> <span class="org-builtin">range</span>(num_epochs):
    <span class="org-keyword">for</span> k <span class="org-keyword">in</span> <span class="org-builtin">range</span>(l):
      <span class="org-variable-name">eta</span> -= np.dot(x, (pip * mean)[k:k + 1].T)
      <span class="org-variable-name">mean</span>[k:k + 1] = (var / residual_var * (xy - x.T.dot(eta))).T
      <span class="org-variable-name">pip</span>[k:k + 1] = (pi * np.exp(.5 * (np.log(var / (effect_var * residual_var)) + np.square(mean[k:k + 1].T) / var))).T
      <span class="org-variable-name">pip</span>[k] /= pip[k].<span class="org-builtin">sum</span>()
      <span class="org-variable-name">eta</span> += np.dot(x, (pip * mean)[k:k + 1].T)
    <span class="org-variable-name">llik</span>, <span class="org-variable-name">kl_z</span>, <span class="org-variable-name">kl_b</span> = elbo(x, y, pip, mean, var, effect_var, residual_var)
    <span class="org-variable-name">update</span> = llik - kl_z - kl_b
    <span class="org-keyword">print</span>(epoch, update, llik, kl_z, kl_b)
    <span class="org-keyword">if</span> elbo_ <span class="org-keyword">is</span> <span class="org-keyword">not</span> <span class="org-constant">None</span> <span class="org-keyword">and</span> (np.isnan(update) <span class="org-keyword">or</span> update &lt;= elbo_):
      <span class="org-keyword">print</span>(<span class="org-string">'Halting'</span>)
      <span class="org-keyword">break</span>
    <span class="org-keyword">else</span>:
      <span class="org-variable-name">elbo_</span> = update
  <span class="org-keyword">return</span> {<span class="org-string">'pip'</span>: pip,
          <span class="org-string">'mean'</span>: mean,
          <span class="org-string">'var'</span>: var,
          <span class="org-string">'elbo'</span>: elbo_}

<span class="org-variable-name">opt</span> = coordinate_ascent(x, y, 1, s.residual_var)
</pre>
</div>

<table>


<colgroup>
<col  class="org-right">

<col  class="org-right">

<col  class="org-right">

<col  class="org-right">

<col  class="org-right">
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">Epoch</th>
<th scope="col" class="org-right">ELBO</th>
<th scope="col" class="org-right">llik</th>
<th scope="col" class="org-right">KL(z)</th>
<th scope="col" class="org-right">KL(b)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">-132745.452102</td>
<td class="org-right">-117713.981064</td>
<td class="org-right">25.352915083</td>
<td class="org-right">15006.1181232</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">-132897.186438</td>
<td class="org-right">-117869.855683</td>
<td class="org-right">25.1308287107</td>
<td class="org-right">15002.1999267</td>
</tr>
</tbody>
</table>
<p>
Halting
</p>
</div>
</div>

<div id="outline-container-orgcd228b8" class="outline-2">
<h2 id="orgcd228b8"><span class="section-number-2">6</span> SGVB on same objective</h2>
<div class="outline-text-2" id="text-6">
<p>
We can optimize the ELBO using gradient descent, but we have to project
\(\pi\) onto the simplex after each iteration. 
</p>

<p>
This solution doesn't appear to select any variables.
</p>

<p>
<b>TODO:</b> what's going on with <code>KL(b)</code>?
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org437dc3a"><span class="org-variable-name">opt</span> = nwas.sgvb.gaussian_categorical_slab(x, y, l=5)
</pre>
</div>

<table>


<colgroup>
<col  class="org-right">

<col  class="org-right">

<col  class="org-right">

<col  class="org-right">

<col  class="org-right">

<col  class="org-right">

<col  class="org-right">

<col  class="org-right">
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">Epoch</th>
<th scope="col" class="org-right">ELBO</th>
<th scope="col" class="org-right">llik</th>
<th scope="col" class="org-right">R</th>
<th scope="col" class="org-right">KL(v)</th>
<th scope="col" class="org-right">KL(v<sub>b</sub>)</th>
<th scope="col" class="org-right">KL(z)</th>
<th scope="col" class="org-right">KL(b)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">-31616.9</td>
<td class="org-right">-8184.2</td>
<td class="org-right">-83.5247</td>
<td class="org-right">1.03809</td>
<td class="org-right">1.03809</td>
<td class="org-right">15764.1</td>
<td class="org-right">7666.5</td>
</tr>

<tr>
<td class="org-right">100</td>
<td class="org-right">-5466.45</td>
<td class="org-right">-21.7072</td>
<td class="org-right">-0.00486338</td>
<td class="org-right">1.06517</td>
<td class="org-right">1.1396</td>
<td class="org-right">18.8546</td>
<td class="org-right">5423.68</td>
</tr>

<tr>
<td class="org-right">200</td>
<td class="org-right">-5081.73</td>
<td class="org-right">-18.489</td>
<td class="org-right">0.00123519</td>
<td class="org-right">1.71877</td>
<td class="org-right">1.03829</td>
<td class="org-right">18.8523</td>
<td class="org-right">5041.63</td>
</tr>

<tr>
<td class="org-right">300</td>
<td class="org-right">-5042.73</td>
<td class="org-right">-18.4033</td>
<td class="org-right">0.00186509</td>
<td class="org-right">2.71956</td>
<td class="org-right">1.01052</td>
<td class="org-right">18.8522</td>
<td class="org-right">5001.75</td>
</tr>

<tr>
<td class="org-right">400</td>
<td class="org-right">-5039.48</td>
<td class="org-right">-16.6873</td>
<td class="org-right">0.000676155</td>
<td class="org-right">2.83859</td>
<td class="org-right">1.00315</td>
<td class="org-right">18.8522</td>
<td class="org-right">5000.1</td>
</tr>

<tr>
<td class="org-right">500</td>
<td class="org-right">-5038.41</td>
<td class="org-right">-15.624</td>
<td class="org-right">0.00157309</td>
<td class="org-right">2.81707</td>
<td class="org-right">1.00042</td>
<td class="org-right">18.8522</td>
<td class="org-right">5000.11</td>
</tr>

<tr>
<td class="org-right">600</td>
<td class="org-right">-5040.08</td>
<td class="org-right">-17.2356</td>
<td class="org-right">0.000780165</td>
<td class="org-right">2.86988</td>
<td class="org-right">1.00021</td>
<td class="org-right">18.8522</td>
<td class="org-right">5000.12</td>
</tr>

<tr>
<td class="org-right">700</td>
<td class="org-right">-5040.78</td>
<td class="org-right">-17.9397</td>
<td class="org-right">0.00160074</td>
<td class="org-right">2.89161</td>
<td class="org-right">1.00254</td>
<td class="org-right">18.8522</td>
<td class="org-right">5000.1</td>
</tr>

<tr>
<td class="org-right">800</td>
<td class="org-right">-5038.4</td>
<td class="org-right">-15.5763</td>
<td class="org-right">0.00114691</td>
<td class="org-right">2.87492</td>
<td class="org-right">1.00723</td>
<td class="org-right">18.8522</td>
<td class="org-right">5000.09</td>
</tr>

<tr>
<td class="org-right">900</td>
<td class="org-right">-5038.51</td>
<td class="org-right">-15.5154</td>
<td class="org-right">0.00095582</td>
<td class="org-right">2.99483</td>
<td class="org-right">1.01352</td>
<td class="org-right">18.8522</td>
<td class="org-right">5000.13</td>
</tr>
</tbody>
</table>

<div class="org-src-container">
<pre class="src src-ipython" id="org0b37bad">opt[0].<span class="org-builtin">max</span>(axis=1), opt[0].argmax(axis=1)
</pre>
</div>

<pre class="example">
(array([ 0.09879258,  0.08785395,  0.09147501,  0.06612478,  0.0979613 ], dtype=float32),
 array([166, 880, 740, 881, 436]))

</pre>
</div>
</div>

<div id="outline-container-org0e00475" class="outline-2">
<h2 id="org0e00475"><span class="section-number-2">7</span> Continuous relaxation</h2>
<div class="outline-text-2" id="text-7">
<p>
In order to make the model amenable to automatic inference, we could use the
ExpConcrete distribution (<a href="https://arxiv.org/abs/1611.00712">Maddison et al 2017</a>, <a href="https://arxiv.org/abs/1611.01144">Jang et al 2017</a>) in place of
the Categorical distribution.
</p>

<p>
We avoid the problem of constrained optimization, but then have to deal with
extra hyperparameters (temperatures).
</p>

<p>
The solution to this relaxed objective doesn't appear to select any
variables, possibly because the KL penalty for \(\mathbf{z}\) is too strong.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="orgd12304b"><span class="org-keyword">def</span> <span class="org-function-name">edward_model</span>(x, y, l, learning_rate=1e-5, temperature=0.1):
  <span class="org-variable-name">y_</span> = y / y.std()
  <span class="org-keyword">with</span> tf.Graph().as_default(), tf.Session(), tf.variable_scope(<span class="org-string">'model'</span>, initializer=tf.random_normal_initializer):
    <span class="org-variable-name">n</span>, <span class="org-variable-name">p</span> = x.shape
    <span class="org-variable-name">x_ph</span> = tf.placeholder(tf.float32)
    <span class="org-variable-name">p_z</span> = ed.models.ExpRelaxedOneHotCategorical(
      temperature=temperature,
      logits=tf.fill([l, p], 1.))
    <span class="org-variable-name">p_b</span> = ed.models.Normal(
      loc=tf.zeros([l, p]),
      scale=nwas.sgvb.biased_softplus(tf.get_variable(<span class="org-string">'s_b'</span>, [1])))
    <span class="org-variable-name">w</span> = tf.transpose(tf.reduce_sum(p_z * p_b, axis=0, keep_dims=<span class="org-constant">True</span>))
    <span class="org-variable-name">p_y</span> = ed.models.Normal(
      loc=tf.matmul(x, w),
      scale=tf.constant(1.))

    <span class="org-variable-name">q_z</span> = ed.models.ExpRelaxedOneHotCategorical(
      temperature=temperature,
      logits=nwas.sgvb.biased_softplus(tf.get_variable(<span class="org-string">'pi'</span>, [l, p])))
    <span class="org-variable-name">q_b</span> = ed.models.Normal(
      loc=tf.get_variable(<span class="org-string">'mu'</span>, [l, p]),
      scale=nwas.sgvb.biased_softplus(tf.get_variable(<span class="org-string">'sigma_b'</span>, [l, p])))

    <span class="org-variable-name">vb</span> = ed.KLqp(latent_vars={p_z: q_z, p_b: q_b}, data={x_ph: x, p_y: y_})
    vb.initialize(optimizer=tf.train.RMSPropOptimizer(learning_rate=learning_rate))
    vb.run()
    <span class="org-keyword">return</span> ed.get_session().run([tf.nn.top_k(q_z.probs, k=10)])

<span class="org-variable-name">opt</span> = edward_model(x, y, l=1)
opt
</pre>
</div>

<pre class="example">
[TopKV2(values=array([[ 0.00781378,  0.00737324,  0.00698482,  0.00644312,  0.00631097,
        0.0053747 ,  0.00509084,  0.00501854,  0.00490211,  0.00486596]], dtype=float32), indices=array([[299, 333, 265, 747, 672, 137, 778, 491, 610, 342]], dtype=int32))]

</pre>
</div>
</div>

<div id="outline-container-org991f5e1" class="outline-2">
<h2 id="org991f5e1"><span class="section-number-2">8</span> Dirichlet-Multinomial model</h2>
<div class="outline-text-2" id="text-8">
<p>
<b>TODO:</b> investigate a potential simplification of the idea:
</p>

<p>
\[ b_j \mid z_j, v, v_b \sim N(0, v^{-1} v_b^{-1}) \]
\[ \mathbf{z} \sim DirichletMultinomial(l, \mathbf{a}) \]
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="orgec99654"><span class="org-keyword">def</span> <span class="org-function-name">dm_model</span>(x, y, max_num_causal, num_iters=5000):
  <span class="org-variable-name">n</span>, <span class="org-variable-name">p</span> = x.shape
  <span class="org-keyword">with</span> tf.Graph().as_default(), tf.Session(), tf.variable_scope(<span class="org-string">'model'</span>, initializer=tf.random_normal_initializer):
    <span class="org-variable-name">max_num_causal</span> = tf.cast(max_num_causal, tf.float32)
    <span class="org-variable-name">x_ph</span> = tf.placeholder(tf.float32)
    <span class="org-variable-name">z</span> = ed.models.DirichletMultinomial(max_num_causal, tf.ones([1, p]))
    <span class="org-variable-name">b</span> = ed.models.Normal(loc=tf.zeros([1, p]), scale=tf.constant(1.))
    <span class="org-variable-name">p_y</span> = ed.models.Normal(loc=tf.matmul(x_ph, z * b, transpose_b=<span class="org-constant">True</span>), scale=tf.cast(y.std() / 2, tf.float32))

    <span class="org-variable-name">q_z</span> = ed.models.Empirical(tf.get_variable(<span class="org-string">'q_z'</span>, [num_iters, 1, p]))
    <span class="org-variable-name">q_b</span> = ed.models.Empirical(tf.get_variable(<span class="org-string">'q_b'</span>, [num_iters, 1, p]))

    <span class="org-variable-name">inference</span> = ed.HMC(latent_vars={z: q_z, b: q_b}, data={x_ph: x, p_y: y})
    inference.run(step_size=0.01)

    <span class="org-keyword">return</span> ed.get_session().run(tf.reshape(q_z.params, [num_iters, p]))

<span class="org-variable-name">trace</span> = dm_model(x, y, 1)
trace.mean(axis=1)[:10]
</pre>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Abhishek Sarkar</p>
<p class="date">Created: 2017-10-30 Mon 18:11</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
